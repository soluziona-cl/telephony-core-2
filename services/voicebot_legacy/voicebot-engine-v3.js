// =========================================================
// VOICEBOT ENGINE V3 - Ultra-Low Latency con Barge-In Real
// =========================================================
// ‚úÖ Sesi√≥n WebSocket persistente (sin reconexi√≥n por turno)
// ‚úÖ Barge-in real con cancelaci√≥n de respuesta OpenAI
// ‚úÖ Detecci√≥n de silencio agresiva (1.5s vs 4s)
// ‚úÖ Timeouts m√°s cortos
// ‚úÖ VAD (Voice Activity Detection) mejorado
// =========================================================

import fs from "fs";
import { exec } from "child_process";
import { promisify } from "util";
import { OpenAIRealtimeClientV3 } from "./voicebot-openai-realtime-v3.js";
import { log } from "../../lib/logger.js";
import config from "./voicebot.config.js";


const execAsync = promisify(exec);

const VOICEBOT_PATH = config.paths.voicebot;
const ASTERISK_REC_PATH = config.paths.recordings;

const MIN_WAV_SIZE_BYTES = config.audio.minWavSizeBytes;
const MAX_TURNS_PER_CALL = config.engine.maxTurns;
const MAX_SILENT_TURNS = config.engine.maxSilentTurns;
const MAX_RECORDING_MS = config.audio.maxRecordingMs;
const PLAYBACK_TIMEOUT_MS = config.audio.playbackTimeoutMs; ///duracion del audio de la respuesta
const SILENCE_THRESHOLD_SEC = config.audio.maxSilenceSeconds;
const TALKING_DEBOUNCE_MS = config.audio.talkingDebounceMs;
const MAX_WAIT_MS = config.audio.maxWaitMs;
const MIN_TALKING_EVENT = config.audio.minTalkingEvents;

const QUEUES_NAME = config.queues.nameQueue;
//const talkingDebounceMs = TALKING_DEBOUNCE_MS;

function shouldTransferToQueue(transcript, assistantResponse = "") {
  if (!transcript) {
    // Si no hay transcript, verificar en la respuesta del asistente
    const lowerResponse = assistantResponse.toLowerCase();
    const transferPhrases = [
      'te conecto con un ejecutivo',
      'te transfiero con un ejecutivo',
      'conectando con ejecutivo',
      'en breve el ejecutivo',
      'te estoy conectando'
    ];

    const shouldTransfer = transferPhrases.some(phrase => lowerResponse.includes(phrase));
    if (shouldTransfer) {
      log("info", `üéØ [Transferencia] Detectada en respuesta del asistente: "${assistantResponse}"`);
    }
    return shouldTransfer;
  }

  const lowerTranscript = transcript.toLowerCase();

  const TRANSFER_KEYWORDS = [
    'ejecutivo', 'operador', 'agente', 'representante', 'asesor', 'vendedor',
    'humano', 'persona', 'hablar con alguien', 'hablar con una persona',
    'derivar', 'transferir', 'pasar con', 'contactar con',
    'colaborador', 'especialista', 'consultor', 'asistente humano',
    'atencion personal', 'atencion directa', 'servicio al cliente',
    'quiero hablar con', 'necesito hablar con', 'deseo hablar con',
    'me comunico con', 'me pongo con', 'me conectas con'
  ];

  const detected = TRANSFER_KEYWORDS.some(keyword => lowerTranscript.includes(keyword));

  if (detected) {
    log("info", `üéØ [Transferencia] Palabra clave detectada: "${transcript}"`);
  }

  return detected;
}


if (!fs.existsSync(VOICEBOT_PATH)) {
  fs.mkdirSync(VOICEBOT_PATH, { recursive: true });
}

// =======================================================
// üé§ DETECCI√ìN DE VOZ MEJORADA - M√°s tolerante
// =======================================================
async function waitForRealVoice(channel, {
  maxWaitMs = MAX_WAIT_MS, // Aumentado de 2s a 4s
  minTalkingEvents = MIN_TALKING_EVENT // M√≠nimo eventos de voz detectados
} = {}) {

  
  return new Promise((resolve) => {
    let talkingCount = 0;
    const start = Date.now();

    const onTalking = (evt, chan) => {
      if (!chan || chan.id !== channel.id) return;
      talkingCount++;

      log("debug", `üé§ Evento de voz detectado (#${talkingCount})`);

      if (talkingCount >= minTalkingEvents) {
        cleanup();
        return resolve({ detected: true, events: talkingCount });
      }
    };

    const cleanup = () => {
      channel.removeListener("ChannelTalkingStarted", onTalking);
    };

    channel.on("ChannelTalkingStarted", onTalking);

    const timer = setInterval(() => {
      const elapsed = Date.now() - start;
      if (elapsed >= maxWaitMs) {
        clearInterval(timer);
        cleanup();
        log("warn", `‚è±Ô∏è Timeout esperando voz (${elapsed}ms)`);
        return resolve({ detected: false, events: talkingCount });
      }
    }, 100);
  });
}

// ---------------------------------------------------------
// Helper: Esperar archivo
// ---------------------------------------------------------
async function waitForFile(path, timeoutMs = 3000, intervalMs = 100) {
  const start = Date.now();

  return new Promise((resolve) => {
    const timer = setInterval(() => {
      try {
        if (fs.existsSync(path)) {
          const stats = fs.statSync(path);
          if (stats.size > 0) {
            clearInterval(timer);
            log("debug", `‚úÖ Archivo encontrado: ${path} (${stats.size} bytes)`);
            return resolve(true);
          }
        }

        if (Date.now() - start > timeoutMs) {
          clearInterval(timer);
          log("warn", `‚è±Ô∏è Timeout esperando archivo: ${path}`);
          return resolve(false);
        }
      } catch (err) {
        log("debug", `Error checking file: ${err.message}`);
      }
    }, intervalMs);
  });
}

// ---------------------------------------------------------
// Helper: Validaci√≥n de grabaci√≥n
// ---------------------------------------------------------
function isValidRecording(path) {
  try {
    if (!fs.existsSync(path)) {
      log("warn", `‚ùå Archivo no existe: ${path}`);
      return false;
    }

    const stats = fs.statSync(path);
    log("debug", `üìÅ Tama√±o grabaci√≥n: ${stats.size} bytes (m√≠n: ${MIN_WAV_SIZE_BYTES})`);

    return stats.size >= MIN_WAV_SIZE_BYTES;
  } catch (err) {
    log("error", `‚ùå Error validando grabaci√≥n: ${err.message}`);
    return false;
  }
}

// ---------------------------------------------------------
// Helper: Convertir WAV
// ---------------------------------------------------------
async function convertWavToWav8000(inputWav, outputWav) {
  try {
    const cmd = `ffmpeg -y -i "${inputWav}" -ar 8000 -ac 1 -codec:a pcm_mulaw "${outputWav}"`;
    log("debug", `[FFmpeg] ${cmd}`);
    await execAsync(cmd);
  } catch (err) {
    throw new Error(`FFmpeg conversion failed: ${err.message}`);
  }
}

// ---------------------------------------------------------
// üîä Reproducir con BARGE-IN y detecci√≥n de interrupciones
// ---------------------------------------------------------
async function playWithBargeIn(ari, channel, fileBaseName, openaiClient) {
  const media = `sound:voicebot/${fileBaseName}`;
  const playback = ari.Playback();

  log("info", `üîä [VB V3] Reproduciendo (barge-in activo): ${media}`);

  return new Promise((resolve) => {
    let bargedIn = false;
    let finished = false;
    let talkingTimer = null;
    const startedAt = Date.now();

    const talkingHandler = (event, chan) => {
      if (!chan || chan.id !== channel.id) return;
      if (finished) return;

      if (talkingTimer) clearTimeout(talkingTimer);

      talkingTimer = setTimeout(() => {
        if (finished) return;

        log("info", `üó£Ô∏è [VB V3] üî• BARGE-IN DETECTADO ‚Üí Usuario interrumpi√≥`);
        bargedIn = true;

        if (openaiClient && openaiClient.activeResponseId) {
          openaiClient.cancelCurrentResponse("user_barge_in");
        }

        playback.stop().catch((err) =>
          log("warn", `‚ö†Ô∏è Error deteniendo playback: ${err.message}`)
        );
      }, TALKING_DEBOUNCE_MS);
    };

    const cleanup = () => {
      finished = true;
      if (talkingTimer) clearTimeout(talkingTimer);
      channel.removeListener("ChannelTalkingStarted", talkingHandler);
    };

    channel.on("ChannelTalkingStarted", talkingHandler);

    playback.on("PlaybackFinished", () => {
      if (finished) return;
      log("debug", `‚úÖ Playback completado: ${media}`);
      cleanup();
      resolve({ reason: bargedIn ? "barge-in" : "finished" });
    });

    playback.on("PlaybackStopped", () => {
      if (finished) return;
      log("debug", `üõë Playback detenido: ${media}`);
      cleanup();
      resolve({ reason: bargedIn ? "barge-in" : "stopped" });
    });

    playback.on("PlaybackFailed", (evt) => {
      if (finished) return;
      log("error", `‚ùå Playback fall√≥: ${JSON.stringify(evt)}`);
      cleanup();
      resolve({ reason: "failed" });
    });

    const timeoutTimer = setInterval(() => {
      if (finished) {
        clearInterval(timeoutTimer);
        return;
      }
      if (Date.now() - startedAt > PLAYBACK_TIMEOUT_MS) {
        log("warn", `‚è∞ Timeout en playback: ${media}`);
        playback.stop().catch((err) =>
          log("warn", `‚ö†Ô∏è Error timeout playback: ${err.message}`)
        );
        clearInterval(timeoutTimer);
      }
    }, 500);

    channel
      .play({ media }, playback)
      .catch((err) => {
        if (finished) return;
        log("error", `‚ùå No se pudo iniciar playback: ${err.message}`);
        cleanup();
        resolve({ reason: "error" });
      });
  });
}

// ---------------------------------------------------------
// üéôÔ∏è Grabar turno
// ---------------------------------------------------------
async function recordUserTurn(channel, turnNumber) {
  const recId = `vb_${Date.now()}`;
  const wavFile = `${ASTERISK_REC_PATH}/${recId}.wav`;

  log("info", `üéôÔ∏è [VB V3] Iniciando grabaci√≥n turno #${turnNumber}: ${recId}`);

  let recordingObj;
  try {
    recordingObj = await channel.record({
      name: recId,
      format: "wav",
      beep: false,
      maxSilenceSeconds: SILENCE_THRESHOLD_SEC,
      silenceThreshold: config.audio.silenceThreshold,
      ifExists: "overwrite"
    });
  } catch (err) {
    log("error", `‚ùå Error grabaci√≥n: ${err.message}`);
    return { ok: false, reason: "record-start-failed" };
  }

  const startedAt = Date.now();

  const result = await new Promise((resolve) => {
    let finished = false;

    const cleanup = () => {
      if (finished) return;
      finished = true;
      recordingObj.removeAllListeners("RecordingFinished");
      recordingObj.removeAllListeners("RecordingFailed");
    };

    recordingObj.on("RecordingFinished", () => {
      if (finished) return;
      const duration = ((Date.now() - startedAt) / 1000).toFixed(2);
      log("info", `üéôÔ∏è [VB V3] Grabaci√≥n finalizada: ${recId}.wav (${duration}s)`);
      cleanup();
      resolve({ ok: true, reason: "finished", duration });
    });

    recordingObj.on("RecordingFailed", (evt) => {
      if (finished) return;
      log("error", `‚ùå [VB V3] RecordingFailed: ${JSON.stringify(evt)}`);
      cleanup();
      resolve({ ok: false, reason: "record-failed" });
    });

    const timer = setInterval(() => {
      if (finished) {
        clearInterval(timer);
        return;
      }
      if (Date.now() - startedAt > MAX_RECORDING_MS) {
        log("warn", `‚è∞ Timeout grabaci√≥n: ${recId}`);
        try {
          recordingObj
            .stop()
            .catch((err) => log("warn", `‚ö†Ô∏è Error timeout: ${err.message}`));
        } catch (err) {
          log("warn", `‚ö†Ô∏è Excepci√≥n timeout: ${err.message}`);
        }
        clearInterval(timer);
      }
    }, 500);
  });

  const exists = await waitForFile(wavFile, 3000, 100);
  if (!exists) {
    log("error", `‚ùå Archivo no existe: ${wavFile}`);
    return { ok: false, reason: "file-not-found" };
  }

  if (!isValidRecording(wavFile)) {
    log("warn", `ü§´ [VB V3] Grabaci√≥n con poco audio: ${wavFile}`);
    return { ok: false, reason: "silence", path: wavFile };
  }

  log("info", `‚úÖ Grabaci√≥n v√°lida: ${wavFile} (${result.duration}s)`);
  return { ok: true, reason: "ok", path: wavFile, recId };
}

// ---------------------------------------------------------
// ü§ñ Procesar turno con OpenAI
// ---------------------------------------------------------
async function processUserTurnWithOpenAI(userWavPath, openaiClient) {
  const recId = `vb_${Date.now()}`;
  const processedUserWav = `${VOICEBOT_PATH}/${recId}_8k.wav`;

  try {
    await convertWavToWav8000(userWavPath, processedUserWav);
  } catch (err) {
    log("error", `‚ùå [VB V3] Error conversi√≥n input‚Üí8k: ${err.message}`);
    return null;
  }

  let responsePcm;
  try {
    log("debug", `üîç [DEBUG] Antes de enviar audio - lastTranscript: "${openaiClient.lastTranscript}"`);
    responsePcm = await openaiClient.sendAudioAndWait(processedUserWav);
    log("debug", `üîç [DEBUG] Despu√©s de enviar audio - lastTranscript: "${openaiClient.lastTranscript}"`);
  } catch (err) {
    log("error", `‚ùå [VB V3] OpenAI error: ${err.message}`);
    return null;
  }

  if (!responsePcm || !responsePcm.length) {
    log("warn", `‚ö†Ô∏è [VB V3] OpenAI devolvi√≥ audio vac√≠o`);
    return null;
  }

  const rspId = `vb_rsp_${Date.now()}`;
  const rawPcmFile = `/tmp/${rspId}.pcm`;
  const finalWavFile = `${VOICEBOT_PATH}/${rspId}.wav`;

  try {
    fs.writeFileSync(rawPcmFile, responsePcm);
  } catch (err) {
    log("error", `‚ùå Error guardando PCM: ${err.message}`);
    return null;
  }

  try {
    const cmd = `ffmpeg -y -f s16le -ar 24000 -ac 1 -i "${rawPcmFile}" -ar 8000 -ac 1 -c:a pcm_s16le "${finalWavFile}"`;
    log("debug", `[FFmpeg] ${cmd}`);
    await execAsync(cmd);
  } catch (err) {
    log("error", `‚ùå Error PCM‚ÜíWAV: ${err.message}`);
    return null;
  }

  log("info", `‚úÖ Respuesta creada: ${finalWavFile}`);
  return rspId;
}

// ---------------------------------------------------------
// üéØ Saludo inicial usando texto
// ---------------------------------------------------------
async function playGreeting(ari, channel, openaiClient) {
  log("info", "üëã [VB V3] Generando saludo inicial...");

  try {
    const audioBuffer = await openaiClient.sendTextAndWait("Hola");

    if (!audioBuffer || audioBuffer.length === 0) {
      log("warn", "‚ö†Ô∏è No se recibi√≥ audio del saludo");
      return false;
    }

    const rspId = `vb_greeting_${Date.now()}`;
    const rawPcmFile = `/tmp/${rspId}.pcm`;
    const finalWavFile = `${VOICEBOT_PATH}/${rspId}.wav`;

    fs.writeFileSync(rawPcmFile, audioBuffer);

    const cmd = `ffmpeg -y -f s16le -ar 24000 -ac 1 -i "${rawPcmFile}" -ar 8000 -ac 1 -c:a pcm_s16le "${finalWavFile}"`;
    log("debug", `[FFmpeg] ${cmd}`);
    await execAsync(cmd);

    log("info", `‚úÖ Saludo generado: ${finalWavFile}`);

    await playWithBargeIn(ari, channel, rspId, openaiClient);

    log("info", "‚úÖ Saludo inicial completado");
    return true;

  } catch (err) {
    log("error", `‚ùå Error generando saludo: ${err.message}`);
    return false;
  }
}

// ---------------------------------------------------------
// üí¨ Prompt "¬øSigues ah√≠?"
// ---------------------------------------------------------
async function playStillTherePrompt(ari, channel, openaiClient) {
  log("info", "‚ùì [VB V3] Reproduciendo prompt: ¬øSigues ah√≠?");

  try {
    const audioBuffer = await openaiClient.sendTextAndWait("¬øSigues ah√≠?");

    if (!audioBuffer || audioBuffer.length === 0) {
      log("warn", "‚ö†Ô∏è No se recibi√≥ audio del prompt");
      return false;
    }

    const rspId = `vb_still_there_${Date.now()}`;
    const rawPcmFile = `/tmp/${rspId}.pcm`;
    const finalWavFile = `${VOICEBOT_PATH}/${rspId}.wav`;

    fs.writeFileSync(rawPcmFile, audioBuffer);

    const cmd = `ffmpeg -y -f s16le -ar 24000 -ac 1 -i "${rawPcmFile}" -ar 8000 -ac 1 -c:a pcm_s16le "${finalWavFile}"`;
    await execAsync(cmd);

    await playWithBargeIn(ari, channel, rspId, openaiClient);

    log("info", "‚úÖ Prompt 'Sigues ah√≠' completado");
    return true;

  } catch (err) {
    log("error", `‚ùå Error en prompt 'Sigues ah√≠': ${err.message}`);
    return false;
  }
}

// ---------------------------------------------------------
// üí¨ Prompt "¬øComprendo?" tras barge-in
// ---------------------------------------------------------
async function playComprendoPrompt(ari, channel, openaiClient) {
  log("info", "‚ùì [VB V3] Reproduciendo prompt: ¬øComprendo?");

  try {
    const audioBuffer = await openaiClient.sendTextAndWait("Disculpa, ¬øcomprendo que quieres interrumpir?");

    if (!audioBuffer || audioBuffer.length === 0) {
      log("warn", "‚ö†Ô∏è No se recibi√≥ audio del prompt");
      return false;
    }

    const rspId = `vb_comprendo_${Date.now()}`;
    const rawPcmFile = `/tmp/${rspId}.pcm`;
    const finalWavFile = `${VOICEBOT_PATH}/${rspId}.wav`;

    fs.writeFileSync(rawPcmFile, audioBuffer);

    const cmd = `ffmpeg -y -f s16le -ar 24000 -ac 1 -i "${rawPcmFile}" -ar 8000 -ac 1 -c:a pcm_s16le "${finalWavFile}"`;
    await execAsync(cmd);

    // No usar barge-in en este prompt (es corto)
    const media = `sound:voicebot/${rspId}`;
    await channel.play({ media }).catch(err =>
      log("warn", `Error reproduciendo prompt comprendo: ${err.message}`)
    );

    log("info", "‚úÖ Prompt 'Comprendo' completado");
    return true;

  } catch (err) {
    log("error", `‚ùå Error en prompt 'Comprendo': ${err.message}`);
    return false;
  }
}

// ---------------------------------------------------------
// üîÑ Transferir a cola de ventas
// ---------------------------------------------------------
async function transferToQueue(ari, channel, queueName = "cola_ventas") {
  log("info", `üìû [VB V3] INICIANDO Transferencia a cola: ${queueName}`);
  log("debug", `üîç [Transferencia] Canal ID: ${channel.id}, Estado: ${channel.state}, LinkedId: ${channel.linkedid}`);

  try {
    // Intentar reproducir mensaje de transferencia
    try {
      await channel.play({
        media: "sound:transfer"
      }).catch(() => {
        log("debug", "Audio de transferencia no disponible, continuando...");
      });

      // Esperar que termine el audio
      await new Promise(resolve => setTimeout(resolve, 2000));
    } catch (err) {
      log("debug", "Sin audio de transferencia, continuando...");
    }

    log("info", `üîÑ [Transferencia] Redirigiendo a contexto: queues, extensi√≥n: ${queueName}`);

    // Redirigir a la cola usando el contexto de dialplan
    await channel.continueInDialplan({
      context: "queues",
      extension: queueName,
      priority: 1
    });

    log("info", `‚úÖ [VB V3] Transferencia a ${queueName} iniciada`);
    return true;

  } catch (err) {
    log("error", `‚ùå [VB V3] Error en transferencia: ${err.message}`);
    log("error", `üîç [Transferencia] Stack trace: ${err.stack}`);
    return false;
  }
}
// ---------------------------------------------------------
// EXPORT: Sesi√≥n VoiceBot V3 MEJORADA CON PROMPTS
// ---------------------------------------------------------
export async function startVoiceBotSessionV3(ari, channel, ani, dnis, linkedId) {
  log(
    "info",
    `ü§ñ[VB ENGINE V3] üöÄ Iniciando sesi√≥n MEJORADA ANI = ${ ani } DNIS = ${ dnis } LinkedId = ${ linkedId } `
  );

  if (!fs.existsSync(VOICEBOT_PATH)) {
    fs.mkdirSync(VOICEBOT_PATH, { recursive: true });
  }

  let sessionActive = true;
  let silentTurns = 0;
  let successfulTurns = 0;

  const openaiClient = new OpenAIRealtimeClientV3({
    voice: config.openai.voice,
    language: config.openai.language,
    model: config.openai.model
  });

  try {
    await openaiClient.connect();
    log("info", `‚úÖ[VB V3] Cliente OpenAI conectado(sesi√≥n persistente)`);
  } catch (err) {
    log("error", `‚ùå[VB V3] Error conectando OpenAI: ${ err.message } `);
    return;
  }

  channel.on("StasisEnd", () => {
    log("info", `üëã[VB V3] Canal colg√≥, finalizando sesi√≥n`);
    sessionActive = false;
    openaiClient.disconnect();
  });

  // ‚úÖ SALUDO INICIAL
  try {
    log("info", "üëã [VB V3] Reproduciendo saludo inicial...");
    await playGreeting(ari, channel, openaiClient);
    await new Promise(resolve => setTimeout(resolve, 500));
  } catch (err) {
    log("warn", `‚ö†Ô∏è Error en saludo inicial: ${ err.message } `);
  }

  for (let turn = 1; sessionActive && turn <= MAX_TURNS_PER_CALL; turn++) {
    log("info", `üîÑ[VB V3] Turno #${ turn } (silencios: ${ silentTurns }/${MAX_SILENT_TURNS})`);

    // =======================================================
    // 1) Esperar voz real (primeros turnos)
    // =======================================================
    if (turn <= 2 && silentTurns === 0) {
      log("info", "üé§ [VB V3] Esperando voz del usuario...");

      const voiceCheck = await waitForRealVoice(channel, {
        maxWaitMs: 4000,
        minTalkingEvents: 1
      });

      if (!voiceCheck.detected) {
        silentTurns++;
        log("warn", `ü§´[VB V3] Sin voz detectada(silencio #${ silentTurns })`);

        // ‚úÖ PROMPT "¬øSIGUES AH√ç?" DESPU√âS DEL SEGUNDO SILENCIO
        if (silentTurns === 2) {
          await playStillTherePrompt(ari, channel, openaiClient);
        }

        if (silentTurns >= MAX_SILENT_TURNS) {
          log("info", "üîö [VB V3] Demasiados silencios, finalizando sesi√≥n");
          break;
        }

        continue;
      }

      log("info", `üü©[VB V3] Voz detectada(${ voiceCheck.events } eventos) ‚Üí iniciando grabaci√≥n`);
    }

    // =======================================================
    // 2) Grabar turno del usuario
    // =======================================================
    const recResult = await recordUserTurn(channel, turn);

    if (!sessionActive) {
      log("info", `üîö[VB V3] Sesi√≥n terminada durante grabaci√≥n`);
      break;
    }

    if (!recResult.ok) {
      if (recResult.reason === "silence") {
        silentTurns++;
        log("info", `ü§´[VB V3] Turno silencioso(#${ silentTurns } / ${ MAX_SILENT_TURNS })`);

        // ‚úÖ PROMPT "¬øSIGUES AH√ç?" DESPU√âS DEL SEGUNDO SILENCIO
        if (silentTurns === 2) {
          await playStillTherePrompt(ari, channel, openaiClient);
        }

        if (silentTurns >= MAX_SILENT_TURNS) {
          log("info", `üîö[VB V3] L√≠mite de silencios alcanzado, cerrando sesi√≥n`);
          break;
        }

        continue;
      }

      log("warn", `‚ö†Ô∏è[VB V3] Error grabaci√≥n(${ recResult.reason }), finalizando`);
      break;
    }

    silentTurns = 0;
    successfulTurns++;
    const userWavPath = recResult.path;

    log("info", `‚úÖ[VB V3] Audio v√°lido recibido(turno exitoso #${ successfulTurns })`);

    // =======================================================
    // 3) Procesar con OpenAI
    // =======================================================
    const responseBaseName = await processUserTurnWithOpenAI(userWavPath, openaiClient);

    if (!sessionActive) {
      log("info", `üîö[VB V3] Sesi√≥n terminada durante OpenAI`);
      break;
    }

    if (!responseBaseName) {
      log("warn", `‚ö†Ô∏è[VB V3] Sin respuesta OpenAI, finalizando`);
      break;
    }


    // ===============================
    // ========================
    // 4) Verificar si se debe transferir a cola
    // =======================================================
    const shouldTransfer = shouldTransferToQueue(
      openaiClient.lastTranscript,
      openaiClient.lastAssistantResponse
    );

    log("debug", `üîç [Transferencia] Verificando: transcript="${openaiClient.lastTranscript}", assistant="${openaiClient.lastAssistantResponse}", shouldTransfer=${shouldTransfer}`);

    if (shouldTransfer) {
      log("info", `üìû[VB V3] Transferencia detectada: "${openaiClient.lastTranscript || openaiClient.lastAssistantResponse}"`);

      const transferred = await transferToQueue(ari, channel, QUEUES_NAME || "cola_ventas");

      if (transferred) {
        log("info", `‚úÖ[VB V3] Sesi√≥n finalizada por transferencia exitosa`);
        break;
      } else {
        log("error", `‚ùå[VB V3] Fall√≥ la transferencia, continuando sesi√≥n`);
      }
    }
    // =======================================================
    // 5) Reproducir respuesta con barge-in
    // =======================================================
    const playbackResult = await playWithBargeIn(ari, channel, responseBaseName, openaiClient);

    if (!sessionActive) {
      log("info", `üîö[VB V3] Sesi√≥n terminada durante playback`);
      break;
    }

    if (playbackResult.reason === "failed" || playbackResult.reason === "error") {
      log("warn", `‚ö†Ô∏è[VB V3] Playback error(${ playbackResult.reason }), finalizando`);
      break;
    }

    // ‚úÖ PROMPT "¬øCOMPRENDO?" AL DETECTAR BARGE-IN
    if (playbackResult.reason === "barge-in") {
      log("info", `üî•[VB V3] Barge -in detectado, reproduciendo prompt de confirmaci√≥n`);
      await playComprendoPrompt(ari, channel, openaiClient);
    }
  }

  openaiClient.disconnect();
  log("info", `üîö[VB ENGINE V3] Sesi√≥n finalizada LinkedId = ${ linkedId } (turnos exitosos: ${ successfulTurns })`);
}