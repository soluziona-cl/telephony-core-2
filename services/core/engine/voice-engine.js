// =========================================================
// VOICEBOT ENGINE V3 - Ultra-Low Latency con Barge-In Real
// =========================================================
// ‚úÖ Sesi√≥n WebSocket persistente (sin reconexi√≥n por turno)
// ‚úÖ Barge-in real con cancelaci√≥n de respuesta OpenAI
// ‚úÖ Detecci√≥n de silencio agresiva (1.5s vs 4s)
// ‚úÖ Timeouts m√°s cortos
// ‚úÖ VAD (Voice Activity Detection) mejorado
// =========================================================


import { exec } from "child_process";
import { promisify } from "util";
import { OpenAIRealtimeClientV3 } from "./openai-client.js";
import { log } from "../../../lib/logger.js";
import { startRecording, stopRecording } from "../telephony/telephony-recorder.js";
import { inboundConfig as config } from "./config.js";
import { buildPrompt } from "./legacy-compat/prompt-builder.js";
import { extractRutFromText, normalizeRut, isValidRut, maskRut, formatRut, parseRutFromSpeech, extractRutHard, cleanAsrNoise } from "./utils.js";
import { getPatientByRut, getAndHoldNextSlot, scheduleAppointment } from "./legacy-compat/db-queries.js";
import { CallFinalizer } from "./services/call-finalizer.js";


// üîß MODULAR ENGINE IMPORTS (Phase 4)
import { SessionContext } from "./core/session-context.js";
import { SilencePolicy } from "./policies/silence-policy.js";
import { HoldPolicy } from "./policies/hold-policy.js";
import { TerminationPolicy } from "./policies/termination-policy.js";
import { ChannelControl } from "./ari/channel-control.js";
import { PlaybackModule } from "./ari/playback.js";
import { RecordingModule } from "./ari/recording.js";
import { EngineRunner } from "./core/engine-runner.js";
import { EngineLogger } from "./telemetry/engine-logger.js";
import { PhaseManager } from "./core/phase-manager.js";
import { playGreeting, playStillTherePrompt, recordUserTurn, sendSystemTextAndPlay, sendBvdaText, extractRutCandidate } from "./legacy/legacy-helpers.js";
import { shouldTransferToQueue, transferToQueue } from "./domain/transfers.js";
import { executeDomainAction } from "./legacy/legacy-actions.js";
import { PHASES, isSilentPhase } from "./domain/phases.js";
import { Guardrails } from "./policies/guardrails.js";
import { ivrSafetyDelay, shortTurnDelay, technicalWorkaroundDelay, recordingSettlementDelay } from "./async/sleep.js";
import { waitPlaybackFinished } from "./async/waiters.js";
import { pollUntil } from "./async/polling.js";
import { SkipInputOrchestrator } from "./orchestration/skip-input-orchestrator.js";
import { StrictModeOrchestrator } from "./orchestration/strict-mode.js";
import { NormalModeOrchestrator } from "./orchestration/normal-mode.js";
import { flowTrace } from "../telemetry/flow-trace.js";

// DB integration and RUT helpers are implemented in the query-enabled engine.

// ‚úÖ DEFINICI√ìN DE FASES Y REQUISITOS (MAPA DE CALOR)
// [EXTRACTED] PHASES and isSilentPhase moved to domain/phases.js



const execAsync = promisify(exec);

const VOICEBOT_PATH = config.paths.voicebot;
const ASTERISK_REC_PATH = config.paths.recordings;

const MIN_WAV_SIZE_BYTES = config.audio.minWavSizeBytes;
const MAX_TURNS_PER_CALL = 20;

/** Instrucci√≥n cr√≠tica para evitar que el bot invente datos si no han sido inyectados */
const ANTI_HALLUCINATION_GUARDRAIL = `
REGLAS CR√çTICAS DE SEGURIDAD:
1. NUNCA inventes RUTs o nombres de pacientes.
2. NUNCA infieras o completes n√∫meros de RUT que el usuario no haya dicho expl√≠citamente. 
3. Si el sistema te indica que el RUT es incompleto, solicita solo la parte faltante.
4. NUNCA des disponibilidad que no haya sido confirmada por el sistema.
5. Mant√©n respuestas breves y formales.
6. Si recibes una instrucci√≥n de sistema (ej. PACIENTE NO ENCONTRADO), rep√≠tela fielmente al usuario sin intentar "arreglarla".
`;
const MAX_SILENT_TURNS = config.engine.maxSilentTurns;
const MAX_RECORDING_MS = config.audio.maxRecordingMs;
const PLAYBACK_TIMEOUT_MS = config.audio.playbackTimeoutMs; ///duracion del audio de la respuesta
const SILENCE_THRESHOLD_SEC = config.audio.maxSilenceSeconds;
const TALKING_DEBOUNCE_MS = config.audio.talkingDebounceMs;
const MAX_WAIT_MS = config.audio.maxWaitMs;
const MIN_TALKING_EVENT = config.audio.minTalkingEvents;

const QUEUES_NAME = config.queues.nameQueue;
//const talkingDebounceMs = TALKING_DEBOUNCE_MS;

// [EXTRACTED] Helpers moved to legacy/legacy-helpers.js

// ---------------------------------------------------------
// üîä Reproducir con BARGE-IN y detecci√≥n de interrupciones
// ---------------------------------------------------------
// [EXTRACTED] ARI Helpers replacement (see legacy-helpers.js)

// ---------------------------------------------------------
// üìù Normalizaci√≥n y Extracci√≥n de RUT can√≥nico
// ---------------------------------------------------------
// ‚úÖ ACTUALIZADO: Usa parseRutFromSpeech() que maneja correctamente millones, miles y DV hablado
// [EXTRACTED] Logic Helpers replacement (see legacy-helpers.js)

// ---------------------------------------------------------
// üéØ Saludo inicial usando texto
// ---------------------------------------------------------
// [EXTRACTED] Domain Helpers replacement (see legacy-helpers.js)

// [EXTRACTED] detectSpecialty moved to legacy-business.js

// ==========================================================================
// üîß MODULAR ENGINE (Phase 4) - Feature Flag Controlled
// ==========================================================================

/**
 * Modular Engine Bootstrap
 * Features:
 * - SessionContext (State Encapsulation)
 * - SilencePolicy (Fail-Closed)
 * - HoldPolicy (MOH w/ Feature Flag)
 * - ChannelControl (Idempotent ARI)
 * - PlaybackModule (Barge-In)
 * - RecordingModule (Validation)
 * - EngineRunner (Clean Loop)
 */
async function runModularEngine(ari, channel, ani, dnis, linkedId, promptFile, domainContext = null) {
  log('info', `üîß [MODULAR ENGINE] Starting session for ${linkedId}`);

  flowTrace({
    traceId: linkedId,
    layer: 'ENGINE',
    flow: 'INIT',
    step: 'START_SESSION',
    depth: 1,
    module: 'voice-engine.js',
    fn: 'runModularEngine',
    action: 'INIT_SESSION',
    result: 'START'
  });

  // 1. Session & Modules
  const session = new SessionContext(linkedId, ani, dnis);
  const logger = new EngineLogger(session);

  const channelControl = new ChannelControl(ari, channel);
  const playback = new PlaybackModule(ari, config.audio);
  const recording = new RecordingModule(config.audio);

  const silencePolicy = new SilencePolicy({
    maxSilentTurns: config.engine.maxSilentTurns,
    failClosed: true
  });

  const holdPolicy = new HoldPolicy(config.engine.hold || {
    enabled: false,
    enterOnFirstSilence: true,
    maxHoldDurationMs: 30000,
    musicClass: 'default'
  });

  const terminationPolicy = new TerminationPolicy();
  const skipInputOrchestrator = new SkipInputOrchestrator({ ari, PHASES });
  const strictModeOrchestrator = new StrictModeOrchestrator({ ari });
  const normalModeOrchestrator = new NormalModeOrchestrator({ ari });
  const phaseManager = new PhaseManager(PHASES, logger);

  // 2. Engine Runner
  const runner = new EngineRunner({
    silencePolicy,
    holdPolicy,
    terminationPolicy,
    playback,
    recording,
    channelControl,
    phaseManager
  }, {
    maxTurns: config.engine.maxTurns || 20,
    PHASES
  }, logger);

  // 3. Legacy State (Compatibility)
  const conversationState = {
    active: true,
    turns: 0,
    history: [],
    lastAssistantText: "",
    repeatedCount: 0,
    startTime: new Date(),
    terminated: false
  };

  const audioState = {
    silentTurns: 0,
    successfulTurns: 0,
    hasSpeech: false
  };

  function botDisablesBargeIn(promptFileName) {
    try {
      const bots = config.bots || {};
      for (const key of Object.keys(bots)) {
        const b = bots[key];
        if (b && b.prompt === promptFileName) return !!b.disableBargeIn;
      }
    } catch (e) { }
    return false;
  }

  // üß† BUSINESS STATE OWNERSHIP: Domain decides initial state
  let businessState = {
    rutPhase: 'NONE',
    disableBargeIn: botDisablesBargeIn(promptFile)
  };

  if (domainContext && typeof domainContext.initialState === 'function') {
    log('info', 'üß© [MODULAR] Initializing State from Domain');
    const domainState = domainContext.initialState();
    businessState = { ...businessState, ...domainState };
  } else if (domainContext && domainContext.initialState && typeof domainContext.initialState === 'object') {
    businessState = { ...businessState, ...domainContext.initialState };
  }

  // 4. OpenAI & Prompting
  function promptRequiresDb(promptFileName) {
    try {
      const bots = config.bots || {};
      for (const key of Object.keys(bots)) {
        const b = bots[key];
        if (b && b.prompt === promptFileName) return !!b.requiresDb;
      }
    } catch (e) { }
    return false;
  }

  const necesitaBDD = promptRequiresDb(promptFile) ? 's√≠' : 'no';
  const systemPrompt = buildPrompt(
    promptFile,
    {
      ANI: ani,
      DNIS: dnis,
      FechaHoy: new Date().toLocaleDateString('es-CL'),
      NecesitaBDD: necesitaBDD,
      NombreCompleto: '[DESCONOCIDO]',
      Edad: '[DESCONOCIDO]',
      EsAdultoMayor: '[DESCONOCIDO]',
      ProximaCita: '[SIN CITAS PENDIENTES]',
      DisponibilidadHoy: '[CONSULTAR AGENDA]',
      RutDetectado: '[NINGUNO]'
    },
    'inbound'
  );

  const openaiClient = new OpenAIRealtimeClientV3({
    voice: config.openai.voice,
    language: config.openai.language,
    model: config.openai.model,
    instructions: ANTI_HALLUCINATION_GUARDRAIL + "\n" + systemPrompt
  });

  await openaiClient.connect();

  // 5. Greeting
  // 5. Greeting
  if (domainContext && domainContext.domain) {
    log("info", "üåâ [MODULAR] Delegating Greeting to Domain (Turn 0)");
    const ctx = {
      transcript: "",
      sessionId: linkedId,
      ani,
      dnis,
      botName: domainContext.botName || 'default',
      state: businessState,
      ari,
      channel
    };

    try {
      const greetingResult = await domainContext.domain(ctx);
      if (ctx.state) Object.assign(businessState, ctx.state);

      if (greetingResult.ttsText) {
        if (greetingResult.ttsText.startsWith('sound:')) {
          const soundId = greetingResult.ttsText.replace('sound:voicebot/', '');
          await playWithBargeIn(ari, channel, soundId, openaiClient, { bargeIn: false });
        } else {
          // TTS din√°mico
          const audioBuffer = await openaiClient.sendSystemText(greetingResult.ttsText);
          if (audioBuffer && audioBuffer.length > 0) {
            const rspId = `vb_greeting_${Date.now()}`;
            const rawPcmFile = `/tmp/${rspId}.pcm`;
            const finalWavFile = `${VOICEBOT_PATH}/${rspId}.wav`;
            fs.writeFileSync(rawPcmFile, audioBuffer);
            const cmd = `ffmpeg -y -f s16le -ar 24000 -ac 1 -i "${rawPcmFile}" -ar 8000 -ac 1 -c:a pcm_s16le "${finalWavFile}"`;
            await execAsync(cmd);
            await playWithBargeIn(ari, channel, rspId, openaiClient, { bargeIn: false });
          }
        }
        if (conversationState) conversationState.history.push({ role: 'assistant', content: greetingResult.ttsText });
      }
    } catch (err) {
      log('error', `‚ö†Ô∏è [MODULAR] Domain Greeting Error: ${err.message}`);
    }
  } else {
    // Legacy Greeting
    const botConfig = config.bots[`voicebot_${promptFile.replace('.txt', '')}`] || config.bots['voicebot'] || {};
    try {
      if (botConfig.greetingFile || botConfig.greetingText) {
        businessState.rutPhase = 'WAIT_BODY';
        await playGreeting(ari, channel, openaiClient, botConfig, conversationState);
        log('info', '‚úÖ [MODULAR] Legacy Greeting completed');
        await technicalWorkaroundDelay();
      }
    } catch (err) {
      log('warn', `‚ö†Ô∏è [MODULAR] Legacy Greeting error: ${err.message}`);
    }
  }

  // 6. Domain Processor Adapter
  const domainProcessor = async (recordResult, session, conversationState, audioState, businessState) => {
    // Process audio
    const responseBaseName = await processUserTurnWithOpenAI(recordResult.path, openaiClient);

    // Get transcript
    const transcript = await waitForTranscript(openaiClient);
    const assistantResponse = openaiClient.lastAssistantResponse || '';

    // History & State
    conversationState.history.push({ role: 'user', content: transcript });
    conversationState.history.push({ role: 'assistant', content: assistantResponse });

    let result = {
      responseFile: responseBaseName,
      assistantResponse: assistantResponse,
      transcript: transcript,
      critical: false,
      nextPhase: businessState.rutPhase || session.currentPhase
    };

    // üß† DOMAIN DELEGATION
    if (domainContext && domainContext.domain) {
      try {
        const ctx = {
          transcript,
          sessionId: linkedId,
          ani,
          dnis,
          botName: domainContext.botName || 'default',
          state: businessState,
          ari,
          channel
        };

        flowTrace({
          traceId: linkedId,
          layer: 'ENGINE',
          flow: businessState.rutPhase || 'UNKNOWN',
          step: session.currentPhase,
          depth: 1,
          module: 'voice-engine.js',
          fn: 'runLoop',
          action: 'DELEGATE_DOMAIN',
          result: domainContext.botName || 'domain'
        });

        const domainResult = await domainContext.domain(ctx);

        // Domain State Update
        if (ctx.state) Object.assign(businessState, ctx.state);

        // Engine Contract Fulfillment
        if (domainResult.ttsText) {
          await openaiClient.sendSystemText(domainResult.ttsText);
          conversationState.history.push({ role: 'assistant', content: domainResult.ttsText });
        }
        if (domainResult.shouldHangup) {
          conversationState.terminated = true;
        }
        result.nextPhase = domainResult.nextPhase || businessState.rutPhase;
        result.critical = false; // Domain handles logic

      } catch (err) {
        log('error', `‚ùå [MODULAR] Domain Logic Error: ${err.message}`);
      }
    } else {
      // üîô LEGACY FALLBACK REMOVED
      // The engine now fully relies on Domain Capsules.
      // If no domain is provided, it will strictly follow the prompt file or fail gracefully.
      log('debug', `[MODULAR] No domain context - skipping business logic`);
    }

    return result;
  };

  // 7. Run Loop
  try {
    await runner.runLoop(
      session,
      channel,
      openaiClient,
      domainProcessor,
      conversationState,
      audioState,
      businessState
    );
  } catch (err) {
    log('error', `‚ùå [MODULAR ENGINE] Fatal: ${err.message}`);
  } finally {
    openaiClient.disconnect();
    log('info', `üîö [MODULAR ENGINE] Session ended`);
    await finalizeCallStorage(ari, channel, ani, dnis, linkedId, conversationState, audioState, businessState).catch(e => log('error', e.message));
  }
}

// ---------------------------------------------------------
// EXPORT: Sesi√≥n VoiceBot V3 MEJORADA CON PROMPTS
// ---------------------------------------------------------
export async function startVoiceBotSessionV3(ari, channel, ani, dnis, linkedId, promptFile, domainContext = null) {
  log(
    "info",
    `ü§ñ[VB ENGINE V3] üöÄ Iniciando sesi√≥n MEJORADA ANI = ${ani} DNIS = ${dnis} LinkedId = ${linkedId} Prompt = ${promptFile}`
  );

  // üîß FEATURE FLAG: Modular Engine
  if (config.engine.useModularEngine) {
    log('info', 'üîß [ENGINE] Using MODULAR engine (Phase 4)');
    return runModularEngine(ari, channel, ani, dnis, linkedId, promptFile, domainContext);
  }

  log('info', 'üîß [ENGINE] Using LEGACY engine');

  if (domainContext && domainContext.domain) {
    log("info", `üîÄ [ENGINE] DomainContext recibido: bot=${domainContext.botName || 'unknown'}, mode=${domainContext.mode || 'unknown'}`);
  } else {
    log("debug", `[ENGINE] Sin DomainContext - usando l√≥gica gen√©rica`);
  }

  if (!fs.existsSync(VOICEBOT_PATH)) {
    fs.mkdirSync(VOICEBOT_PATH, { recursive: true });
  }

  // =======================================================
  // PROMPT DIN√ÅMICO DESDE TXT (nuevo)
  // =======================================================
  // Construir prompt base y a√±adir flag que indica si el prompt necesita BDD
  function promptRequiresDb(promptFileName) {
    try {
      const bots = config.bots || {};
      for (const key of Object.keys(bots)) {
        const b = bots[key];
        if (b && b.prompt === promptFileName) return !!b.requiresDb;
      }
    } catch (e) { }
    return false;
  }

  // üõ°Ô∏è Detectar si el bot deshabilita barge-in (para adultos mayores)
  function botDisablesBargeIn(promptFileName) {
    try {
      const bots = config.bots || {};
      for (const key of Object.keys(bots)) {
        const b = bots[key];
        if (b && b.prompt === promptFileName) return !!b.disableBargeIn;
      }
    } catch (e) { }
    return false;
  }

  const necesitaBDD = promptRequiresDb(promptFile) ? 's√≠' : 'no';
  const botNoBargeIn = botDisablesBargeIn(promptFile); // üõ°Ô∏è Flag para deshabilitar barge-in

  // üõ°Ô∏è HARDENING OBLIGATORIO: Verificar helper isSilentPhase
  if (typeof isSilentPhase !== 'function') {
    log("error", '[ENGINE] CRITICAL: isSilentPhase helper no definido. Abortando para evitar crash.');
    return { shouldHangup: true };
  }


  const systemPrompt = buildPrompt(
    promptFile, // archivo dentro de inbound/prompts/
    {
      ANI: ani,
      DNIS: dnis,
      FechaHoy: new Date().toLocaleDateString('es-CL'),
      NecesitaBDD: necesitaBDD,
      // Valores por defecto para evitar alucinaciones si no hay datos iniciales
      NombreCompleto: '[DESCONOCIDO]',
      Edad: '[DESCONOCIDO]',
      EsAdultoMayor: '[DESCONOCIDO]',
      ProximaCita: '[SIN CITAS PENDIENTES]',
      DisponibilidadHoy: '[CONSULTAR AGENDA]',
      RutDetectado: '[NINGUNO]'
    },
    'inbound'
  );

  // Insertamos instrucciones en el cliente
  log("info", "üìÑ [PROMPT] Prompt cargado desde TXT para inbound");


  // =======================================================
  // üß© ESTADOS DE SESI√ìN (Redise√±o Estructura Mixta)
  // =======================================================
  const conversationState = {
    active: true,
    turns: 0,
    history: [], // [{role, content}]
    turns: 0,
    history: [], // [{role, content}]
    lastAssistantText: "",
    repeatedCount: 0,
    startTime: new Date(),
    terminated: false // V3-F04: Flag de sesi√≥n terminada
  };

  const audioState = {
    silentTurns: 0,
    successfulTurns: 0,
    hasSpeech: false
  };

  const businessState = {
    rutPhase: 'NONE', // 'NONE', 'WAIT_BODY', 'WAIT_DV', 'COMPLETE', 'ERROR'
    rutBody: null,
    rutDv: null,
    rutFormatted: null, // RUT completo formateado desde webhook FORMAT_RUT
    rutAttempts: 0,
    dni: null,
    patient: null,
    nombre_paciente: null, // Nombre desde webhook VALIDATE_PATIENT
    specialty: null,
    especialidad: null, // Especialidad detectada
    fecha_hora: null, // Fecha y hora desde webhook GET_NEXT_AVAILABILITY
    doctor_box: null, // Doctor desde webhook GET_NEXT_AVAILABILITY
    heldSlot: null,
    requiresStrictTts: false,
    disableBargeIn: botNoBargeIn // üõ°Ô∏è Deshabilitar barge-in si el bot lo requiere
  };

  const openaiClient = new OpenAIRealtimeClientV3({
    voice: config.openai.voice,
    language: config.openai.language,
    model: config.openai.model,
    instructions: ANTI_HALLUCINATION_GUARDRAIL + "\n" + systemPrompt
  });

  try {
    await openaiClient.connect();
  } catch (err) {
    log("error", `‚ùå [VB V3] No se pudo conectar a OpenAI Realtime: ${err.message}`);
  }
  // Mantener el comportamiento original del motor V3: no inyectar prompts espec√≠ficos del DB.

  channel.on("StasisEnd", () => {
    log("info", `üëã[VB V3] Canal colg√≥, finalizando sesi√≥n`);
    conversationState.active = false;
    openaiClient.disconnect();
  });

  // üéôÔ∏è [MASTER] La grabaci√≥n ahora es gestionada por MixMonitor en Asterisk (dialplan)
  // Se encarga de capturar el audio mezclado (bot + usuario) de forma robusta.
  log("info", `üéôÔ∏è [VB V3] MixMonitor activo para grabaci√≥n master FULL-MIX`);
  /*
  try {
    const tenantId = process.env.TENANT_ID || "1";
    const { name: recName } = await startRecording(ari, channel, tenantId, linkedId, ani, dnis);
    if (recName) {
      log("info", `üéôÔ∏è [VB V3] Grabaci√≥n principal garantizada: ${recName}`);
    }
  } catch (err) {
    log("warn", `‚ö†Ô∏è [VB V3] Error al asegurar grabaci√≥n: ${err.message}`);
  }
  */

  // ‚úÖ SALUDO INICIAL
  try {
    log("info", "üëã [VB V3] Reproduciendo saludo inicial...");

    // üîÄ DELEGACI√ìN AL DOMINIO (si existe c√°psula)
    if (domainContext && domainContext.domain) {
      log("info", "üåâ [ENGINE] Delegando saludo inicial al dominio (Turn 0)");

      const ctx = {
        transcript: "", // Sin input en Turn 0
        sessionId: linkedId,
        ani,
        dnis,
        botName: domainContext.botName || 'default',
        state: businessState,
        ari,
        channel
      };

      const greetingResult = await domainContext.domain(ctx);

      // Actualizar businessState con el estado del dominio
      if (ctx.state) {
        Object.assign(businessState, ctx.state);
      }

      // Si el dominio devuelve ttsText, reproducirlo
      if (greetingResult.ttsText) {
        // Verificar si es un sound file (formato: sound:voicebot/filename)
        if (greetingResult.ttsText.startsWith('sound:')) {
          const soundId = greetingResult.ttsText.replace('sound:voicebot/', '');
          log("info", `üîä [ENGINE] Reproduciendo audio est√°tico del dominio: ${soundId}`);
          await playWithBargeIn(ari, channel, soundId, openaiClient, { bargeIn: false });
        } else {
          // TTS din√°mico
          log("info", `ü§ñ [ENGINE] Generando TTS del dominio: ${greetingResult.ttsText.substring(0, 50)}...`);
          const audioBuffer = await openaiClient.sendSystemText(greetingResult.ttsText);
          if (audioBuffer && audioBuffer.length > 0) {
            const rspId = `vb_greeting_${Date.now()}`;
            const rawPcmFile = `/tmp/${rspId}.pcm`;
            const finalWavFile = `${VOICEBOT_PATH}/${rspId}.wav`;
            fs.writeFileSync(rawPcmFile, audioBuffer);
            const cmd = `ffmpeg -y -f s16le -ar 24000 -ac 1 -i "${rawPcmFile}" -ar 8000 -ac 1 -c:a pcm_s16le "${finalWavFile}"`;
            await execAsync(cmd);
            await playWithBargeIn(ari, channel, rspId, openaiClient, { bargeIn: false });
          }
        }

        // Registrar en historial
        if (conversationState) {
          conversationState.history.push({ role: 'assistant', content: greetingResult.ttsText });
        }
      }

      log("info", "‚úÖ Saludo inicial completado (dominio)");
      await technicalWorkaroundDelay();
    } else {
      // üîô LEGACY: Usar l√≥gica actual del engine
      log("info", "üîô [ENGINE] Usando saludo legacy (sin dominio)");

      // Obtener configuraci√≥n del bot basado en el promptFile
      let botConfig = {};
      const bots = config.bots || {};
      for (const key of Object.keys(bots)) {
        if (bots[key]?.prompt === promptFile) {
          botConfig = bots[key];
          break;
        }
      }

      // Inicializar fase RUT si el bot lo requiere
      businessState.rutPhase = 'WAIT_BODY';

      await playGreeting(ari, channel, openaiClient, botConfig, conversationState);
      log("info", "‚úÖ Saludo inicial completado");
      await technicalWorkaroundDelay();
    }
  } catch (err) {
    log("warn", `‚ö†Ô∏è Error en saludo inicial: ${err.message} `);
  }

  for (let turn = 1; conversationState.active && turn <= MAX_TURNS_PER_CALL; turn++) {
    conversationState.turns = turn;

    // V3-F04: Guard global
    if (conversationState.terminated) {
      log("info", "[ENGINE] Sesi√≥n terminada, deteniendo loop");
      break;
    }



    log("info", `üîÑ[VB V3] Turno #${turn} (silencios: ${audioState.silentTurns}/${MAX_SILENT_TURNS})`);

    // Limpiar transcripciones previas para evitar falsos positivos en l√≥gica de transferencia/RUT
    openaiClient.lastTranscript = "";
    openaiClient.lastAssistantResponse = "";
    let assistantResponse = "";

    // üõ°Ô∏è Verificar si el dominio indica que NO debe esperar voz (skipUserInput)
    // Esto es gen√©rico: cualquier dominio puede indicar fases silenciosas
    // ‚úÖ ORCHESTRATION: Check for silent phase / skip input / auto-advance (Phase 10)
    const skipResult = await skipInputOrchestrator.checkAndExecute(
      channel,
      openaiClient,
      domainContext,
      businessState,
      conversationState,
      turn,
      linkedId
    );

    if (skipResult.shouldSkip) {
      continue;
    }


    // =======================================================
    // 1) Turno inicial: Pregunta Proactiva del Bot (Solo turno 1)
    // =======================================================
    // ‚úÖ ELIMINADO: El saludo inicial ahora incluye la solicitud de RUT
    // por lo que no necesitamos un turno proactivo separado.
    /*
    if (turn === 1 && !audioState.hasSpeech) {
      log("info", "üé§ [VB V3] Turno 1: Bot inicia solicitud de RUT (Protegido + Keep-Alive)");
  
      // üîí Turno 1 proactive: NO interrumpible (BVDA)
      // Usamos una ruta fija para el primer mensaje si es com√∫n, para evitar latencia de OpenAI en Turno 1
      const turn1Text = "Para comenzar, por favor ind√≠queme los n√∫meros de su RUT, sin el d√≠gito verificador.";
      const turn1CachePath = `${VOICEBOT_PATH}/turn1_rut_request.wav`;
  
      if (fs.existsSync(turn1CachePath)) {
        log('info', 'üìÇ [CACHE] Usando audio local para solicitud de RUT Turno 1');
        await playWithBargeIn(ari, channel, 'turn1_rut_request', openaiClient, { bargeIn: false });
      } else {
        await sendBvdaText(ari, channel, openaiClient, turn1Text);
      }
    }
    */

    // =======================================================
    // 2) Esperar voz real
    // =======================================================
    // üõ°Ô∏è GUARDRAIL: Si es fase silenciosa, saltar grabaci√≥n
    if (shouldSkipUserInput) {
      log("info", `üîá [ENGINE] Fase silenciosa detectada (skipUserInput=true), saltando grabaci√≥n expl√≠citamente`);
      audioState.silentTurns = 0; // Resetear silencios para no triggerar timeout
      continue;
    }

    // üõ°Ô∏è GUARDRAIL: Permitir espera de voz en fases cr√≠ticas incluso si Turn > 2
    // üõ°Ô∏è GUARDRAIL: Permitir espera de voz en fases cr√≠ticas incluso si Turn > 2
    const currentPhaseDef = PHASES[businessState.rutPhase] || {};
    const isCriticalPhase = currentPhaseDef.isCritical || false;

    if ((turn <= 2 || isCriticalPhase) && audioState.silentTurns === 0) {
      log("info", "üé§ [VB V3] Esperando voz del usuario...");

      const voiceCheck = await waitForRealVoice(channel, {
        maxWaitMs: 4000,
        minTalkingEvents: 1
      });

      if (conversationState.terminated) {
        log("info", "[ENGINE] Sesi√≥n terminada mientras se esperaba voz. Abortando.");
        break;
      }

      if (!voiceCheck.detected) {
        log("warn", `ü§´[VB V3] Sin voz detectada`);

        const silenceResult = silencePolicy.evaluate(session, false);

        if (silenceResult.action === 'prompt') {
          await playStillTherePrompt(ari, channel, openaiClient);
        } else if (silenceResult.action === 'goodbye') {
          await terminationPolicy.terminate(session, channelControl, 'max_silence');
          conversationState.active = false;
          break;
        }

        // Update local legacy state for logging consistency if needed, 
        // but session context is the source of truth now.
        audioState.silentTurns = session.consecutiveSilences;

        continue;
      } else {
        // Reset silence policy on voice detected
        silencePolicy.evaluate(session, true);
        audioState.silentTurns = 0;
      }

      log("info", `üü©[VB V3] Voz detectada(${voiceCheck.events} eventos) ‚Üí iniciando grabaci√≥n`);
    }

    // =======================================================
    // 2) Grabar turno del usuario
    // =======================================================
    const recResult = await recordUserTurn(channel, turn);

    // V3-F05: Post-Termination Guard
    if (conversationState.terminated) {
      log("info", "[ENGINE] Sesi√≥n terminada durante grabaci√≥n. Ignorando resultado.");
      break;
    }

    if (!conversationState.active) {
      log("info", `üîö[VB V3] Sesi√≥n terminada durante grabaci√≥n`);
      break;
    }

    if (!recResult.ok) {
      if (recResult.reason === "silence") {
        log("warn", `ü§´[VB V3] Grabaci√≥n vac√≠a/silencio detected`);

        const silenceResult = silencePolicy.evaluate(session, false);

        if (silenceResult.action === 'prompt') {
          await playStillTherePrompt(ari, channel, openaiClient);
        } else if (silenceResult.action === 'goodbye') {
          await terminationPolicy.terminate(session, channelControl, 'max_silence');
          conversationState.active = false;
          break;
        }

        // Update local legacy state
        audioState.silentTurns = session.consecutiveSilences;
        continue;
      }

      log("warn", `‚ö†Ô∏è[VB V3] Error grabaci√≥n(${recResult.reason}), finalizando`);
      conversationState.active = false;
      break;
    }

    audioState.silentTurns = 0;
    audioState.successfulTurns++;
    audioState.hasSpeech = true;
    const userWavPath = recResult.path;

    // VALIDAR TAMA√ëO M√çNIMO (Evitar procesar audios vac√≠os/planos)
    const stats = fs.statSync(userWavPath);
    if (stats.size < 40000) { // 40KB m√≠nimo recomendado para RTP WebRTC real
      log("warn", `‚ö†Ô∏è[VB V3] Turno con poco audio (${stats.size} bytes), posiblemente mudo.`);
      // Opcionalmente podr√≠as decidir no enviarlo a OpenAI
    }

    log("info", `‚úÖ[VB V3] Audio v√°lido recibido(turno exitoso #${audioState.successfulTurns}, ${stats.size} bytes)`);

    // =======================================================
    // 3) Procesamiento Central: STRICT MODE vs NORMAL MODE
    // =======================================================
    // Si estamos en una fase delicada (RUT), usamos STRICT MODE (Transcribe -> Logic -> TTS Explicit)
    // Si no, usamos NORMAL MODE (Realtime Audio-to-Audio)

    let responseBaseName = null;
    let transcript = "";

    // Nota: La verificaci√≥n de fases silenciosas ya se hizo al inicio del turno
    // Si llegamos aqu√≠, NO es fase silenciosa, as√≠ que procesamos normalmente

    // --- MODO ESTRICTO (RUT) ---
    // Nota: Si llegamos aqu√≠, el dominio NO indic√≥ skipUserInput (ya se proces√≥ al inicio del turno)
    // Procesamos normalmente con transcripci√≥n de audio
    // --- MODO ESTRICTO (RUT) phase-driven ---
    // If we are in a phase that requires specific handling (Strict), delegation is now simplified.
    if (businessState.rutPhase !== 'NONE' && businessState.rutPhase !== 'COMPLETE' && businessState.rutPhase !== 'ERROR') {
      const strictResult = await strictModeOrchestrator.execute(
        channel,
        openaiClient,
        domainContext,
        businessState,
        conversationState,
        turn,
        linkedId,
        userWavPath,
        promptFile
      );

      if (strictResult.terminated) {
        conversationState.active = false;
      }

      // El modo estricto maneja su propio playback internamente, continuar loop
      continue;
    }
    // --- MODO NORMAL (Conversacional) ---
    else {
      const normalResult = await normalModeOrchestrator.execute(
        channel,
        openaiClient,
        businessState,
        conversationState,
        turn,
        linkedId,
        userWavPath
      );

      if (!normalResult.active) {
        conversationState.active = false;
        // Logic loop condition will handle termination, or we can break if needed
      }
    }






  }

  openaiClient.disconnect();
  log("info", `üîö[VB ENGINE V3] Sesi√≥n finalizada LinkedId = ${linkedId} (turnos exitosos: ${audioState.successfulTurns})`);

  // Finalizar almacenamiento e inicio de registro SQL (async)
  CallFinalizer.finalize(ari, channel, conversationState, audioState, businessState).catch(err => {
    log("error", `‚ùå [FINALIZE] Error fatal en finalizaci√≥n: ${err.message}`);
  });
}

/**
 * üß± HARD STATE MACHINE: L√≥gica determinista para RUT
 * Decide qu√© texto decir (TTS) y c√≥mo cambiar de estado.
 */

// --- Helper Functions de Negocio ---
// [EXTRACTED] State Logic moved to legacy/legacy-business.js

// [EXTRACTED] Business Logic moved to legacy/legacy-business.js
